Personal AI Assistant Overview
The system is a comprehensive personal assistant that integrates with WhatsApp, Google services, and uses AI to understand requests. Here's a breakdown of the key components:



Core Structure

1) Main Components

WhatsApp Integration: Uses Twilio to send/receive messages
NLP Processing: Analyzes user messages to identify intents and extract entities
Service Integration: Connects with Google APIs (Calendar, Gmail, Contacts)
Database: Local SQLite DB for caching contacts and state management



2) File Organization

app/main.py: Entry point with two modes - CLI testing and Twilio WhatsApp mode
app/config.py: Configuration and environment variables (API keys, timezone settings)
app/whatsapp/: WhatsApp integration components
app/nlp/: Natural language processing modules
app/services/: Google API service wrappers
app/utils/: Helper utilities


Key Files and Their Functions

1) WhatsApp Integration

twilio_client.py: Handles communication with Twilio's API for sending/receiving WhatsApp messages
webhook_server.py: Flask server that processes incoming webhook events from Twilio
message_handler.py: Core logic for processing incoming messages and managing conversation flow


2) NLP Processing

intent_recognizer.py: Classifies user messages into intents (email, meeting, calendar, etc.)

Uses OpenRouter API (GPT-4o-mini) with fallback to transformer models
Includes rule-based backup for robustness


entity_extractor.py: Extracts key information like names, dates, times from messages

Uses OpenRouter API with fallback to transformer models
Has specialized extractors for different entity types



3) Service Integration

email_service.py: Sends emails and retrieves inbox information via Gmail API
calendar_service.py: Manages calendar events via Google Calendar API

Handles scheduling, free time checking, and calendar queries


contacts_service.py: Retrieves contact information via Google People API

Implements smart contact matching with multi-tier results


contacts_db_service.py: Local cache of contacts for offline access and better searching

4) Utilities

auth.py: Handles Google API authentication and token management
helpers.py: Common utility functions for date/time formatting, validation, etc.
llm.py: The llm.py file is used to handle all interactions with 
Large Language Models through OpenRouter. Its main functions include:
          Intent Recognition: It sends user messages to OpenRouter's API (using GPT-4o-mini) 
                             to classify what the user wants to do (send email, check calendar, etc.)
          Entity Extraction: It extracts specific details from user messages like names, dates, times, 
                             and email addresses

Key Workflows


1) Meeting Scheduling

User requests to schedule a meeting
System asks for attendee, date, and time
Validates input (especially email format)
Checks calendar for conflicts
Offers alternative times if needed
Creates the calendar event

2) Email Sending

User asks to send an email
System collects recipient, subject, and body
Validates email format with smart correction
Sends email via Gmail API

3) Calendar Checking

User asks about their schedule
System extracts date information
Retrieves and formats calendar events

4) Contact Lookup

User asks for contact information
System searches Google Contacts with tiered matching
Falls back to local database if needed
Returns contact details with proper formatting

Technical Features

Conversation State Management: Handles multi-step conversations
Fallback Mechanisms: Multiple levels of fallbacks for robustness
Rate Limit Handling: Manages Google API rate limits with resumable operations
Input Validation: Smart validation with suggestions for corrections
Error Handling: Graceful degradation when services are unavailable

Design Philosophy
The system follows a tiered approach to processing:

First tries advanced AI (OpenRouter/GPT-4o-mini)
Falls back to transformer models if AI is unavailable
Uses rule-based approaches as final fallback

This ensures the assistant works reliably even when cloud services are unavailable, 
while providing sophisticated understanding when possible.



In Personal AI assistant, we do have a backend system, but it's not a traditional 
web backend with a separate client-server architecture. Instead, 
we have a self-contained Python application that serves as the backend with these components:

Flask server - The webhook_server.py file creates a minimal web server that handles incoming 
               webhook requests from Twilio
SQLite database - The contacts_db_service.py implements a local database that serves as 
                  persistent storage for contacts
API client layer - Your code interacts with multiple external APIs:

Google APIs (Gmail, Calendar, Contacts)
Twilio API for WhatsApp messaging
OpenRouter API for AI capabilities


State management - You maintain conversation state in memory using the user_state dictionary

The application functions as a backend system that:

Processes incoming requests (messages)
Maintains state between interactions
Stores and retrieves data
Communicates with external services
Returns responses to users

It's a complete backend system, just packaged as a standalone application rather than being 
split into separate client and backend components